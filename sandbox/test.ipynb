{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/armeltalla/Documents/CAI/SDKs/clipsai/data\n",
      "['/Users/armeltalla/Documents/CAI/SDKs/clipsai/clipsai', '/Users/armeltalla/Documents/CAI/SDKs/clipsai/clipsai', '/Users/armeltalla/Documents/CAI/SDKs/clipsai/clipsai', '/Users/armeltalla/Documents/CAI/SDKs/clipsai', '/Users/armeltalla/Documents/CAI/SDKs/clipsai/clipsai', '/Users/armeltalla/Documents/CAI/SDKs/clipsai/sandbox', '/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/armeltalla/Documents/CAI/SDKs/clipsai/env/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "DATA_PATH = os.path.abspath(os.path.join(\"..\", \"data\"))\n",
    "print(DATA_PATH)\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(\"..\"))\n",
    "SRC_PATH = os.path.join(ROOT_PATH, \"clipsai\")\n",
    "sys.path.insert(0, SRC_PATH)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resize.resize import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_path = os.path.join(DATA_PATH, \"aod.mp4\")\n",
    "pyannote_auth_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyscenedetect:Downscale factor set to 8, effective resolution: 276 x 155\n",
      "INFO:pyscenedetect:Detecting scenes...\n",
      "I0000 00:00:1704318752.719658       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2 Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crops:  Crops(Original: (2208x1242), Resized: (698x1242), Segments: [Segment(speakers: [0], start: 0.0, end: 29.75, coordinates: (336, 6)), Segment(speakers: [1], start: 29.75, end: 31.083333, coordinates: (626, 6)), Segment(speakers: [1], start: 31.083333, end: 96.646859, coordinates: (329, 0)), Segment(speakers: [0], start: 96.646859, end: 103.5, coordinates: (1159, 0)), Segment(speakers: [0], start: 103.5, end: 109.5, coordinates: (808, 0)), Segment(speakers: [0], start: 109.5, end: 149.142615, coordinates: (1181, 0)), Segment(speakers: [0], start: 149.142615, end: 156.633333, coordinates: (333, 14)), Segment(speakers: [0], start: 156.633333, end: 157.316667, coordinates: (640, 14)), Segment(speakers: [0], start: 157.316667, end: 180.195246, coordinates: (1175, 0)), Segment(speakers: [1], start: 180.195246, end: 260.24618, coordinates: (334, 0)), Segment(speakers: [0], start: 260.24618, end: 267.266667, coordinates: (1127, 0))])\n"
     ]
    }
   ],
   "source": [
    "crops = resize(\n",
    "    video_file_path=video_file_path,\n",
    "    pyannote_auth_token=pyannote_auth_token,\n",
    "    aspect_ratio=(9, 16)\n",
    ")\n",
    "print()\n",
    "print(\"Crops: \", crops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSCRIBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcribe.transcribe import transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.1.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.1.2. Bad things might happen unless you revert torch to 1.x.\n",
      "Detected language: en (1.00) in first 30s of audio...\n",
      "\n",
      "And I'll second, this is probably, I think you can talk about this second point, because I feel like you have a better mastery of being okay with this, because I'm very bad at this. The second point is a new port title that embraced boredom. And basically what this is, his first point was really that we should be taking a break from focusing, not taking a break from distractions. And so we have so many distractions in our lives, whether it be your phone. I don't want to call your friends a distraction, but in a way, in some ways they are. And you have to, oh no. They are distractions. You know, there are so many ways that you can be distracted in life and so we need to be able to sit down and do work. And if you can get in the habit of just focusing and then taking a break from that focus to do maybe five or ten minutes you go screw around, listen to music, go watch YouTube video, go watch Codico or something I don't know, whatever floats your bowbrake. The point here was that we are so overstimulated. And so you need to be able to be okay with actually being bored sometimes as well. So you don't always need to be filled with the most entertaining thing. You don't always need to be walking around something new information. We have this affinity with novelty every day. We want to have something new, something that's with us all the time. be okay was like not thinking about literally anything be okay with like walking around and just being with your own thoughts in your own way one and that's gonna help you focus and be actually just to be better person we're gonna have to do the medicine we're gonna have to do a meditation episode because that's that's exactly what meditation is be okay with your thoughts running to your head that's why I shower a lot because one I want to be clean but two I just like thinking deeply okay but I also think on that point to it's like You know that you have not embraced boredom when your phone buzzes and you just automatically grab it. That's true. Like, unless you know like the notification is a text, like, but if it's just like some random buzz or yeah, and you just like instantly grab it, because you're like on board, you have not embraced boredom. And you are a, you your phone controls you. Yeah, no, if you're, if you are reflective to your phone, if you anytime you get bored, you know, if you're to social event or you're outside and you know, you're like, oh, I don't know what to talk to or whatever, and you immediately reach for your phone, who's controlling you? You your phone just a question not a not judge and just it's just a question all I'm saying is habits are for loops happening in the background and your phone has control of that for loop now Some people will get that some people won't most people won't I told to see I told some other person I was interning with that use another like coder and he was like you know you blew my mind I was like I know because I was trying to prove to him simulation But on to something more similar to that, and that's social media. Oh my, okay. Over this progression this podcast, I might start sounding like Ben. Is that a bad thing or a good thing? Depends who you are. That's fair. Yeah, so social media guys. I don't want to be too harsh on you, but basically we have a lot of tools at our disposal in life. Social media and our phones is one of them and they can be used for good or for bad. And I would argue that most people do not use them well. And the point here is that when you are doing work, any time you switch from one task to another, there's what's called attention residue. So that means that it's going to take you around 15 to 20 minutes to be able to fully immerse yourself into the work that you're going to be able to do. And any time you go to check your phone, any time you go, you get distracted real quick, that's going to reset that tension residue, and now you can't focus. So if you're in the middle of work and you check your phone, for example, and then you see something on Instagram and you're like, oh my gosh, my friends are having fun, and then now you're thinking about them. Now you're not thinking about math problems. Now your deep work is just you're done. So the point here is not that social media is inherently bad. The point here is that it is a huge distraction or it can be, so just use it wisely and make sure that when you're doing work, it is not distracting you. Okay. Put it, put your phone in a different room, different corner, you know, whatever, turn it all the way off. Whatever you need to do, make sure that it's not taking up your focus time for you work. And ask yourself this question. Why am I using it? Just like ask yourself that.\n"
     ]
    }
   ],
   "source": [
    "transcription = transcribe(video_file_path)\n",
    "print()\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clip.clip import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = clip(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip(start_time=0, end_time=267.2, start_char=0, end_char=4726)\n",
      "Clip(start_time=0.009, end_time=175.887, start_char=0, end_char=3073)\n",
      "Clip(start_time=175.106, end_time=197.823, start_char=3061, end_char=3425)\n",
      "Clip(start_time=194.301, end_time=259.536, start_char=3341, end_char=4646)\n",
      "Clip(start_time=0.009, end_time=197.823, start_char=0, end_char=3425)\n"
     ]
    }
   ],
   "source": [
    "for clip in clips:\n",
    "    print(clip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
